\chapter{Related Work}

%\subsubsection{Psychoacoustic Features and Gray Codes}

% This chapter covers relevant (and typically, recent) research
% which you build upon (or improve upon). There are two complementary
% goals for this chapter:
% \begin{enumerate}
%   \item to show that you know and understand the state of the art; and
%   \item to put your work in context
% \end{enumerate}

% Ideally you can tackle both together by providing a critique of
% related work, and describing what is insufficient (and how you do
% better!)

% The related work chapter should usually come either near the front or
% near the back of the dissertation. The advantage of the former is that
% you get to build the argument for why your work is important before
% presenting your solution(s) in later chapters; the advantage of the
% latter is that don't have to forward reference to your solution too
% much. The correct choice will depend on what you're writing up, and
% your own personal preference.

Eck Schmidhuber \todo{Cite} LSTM blues wrap data around to only a single octave, don't
model when a note is released.

Boulanger sampled at every quarter note for JCB: we do every 8th \todo{or 16th?}

Machine learning on music has a rich history in classification and analysis tasks.
\cite{Herlands2014} describe a system to classify music style.

\cite{Eck2002} first looked at LSTMs for music composition, noting a lack of global
structure and long-range dependencies. The same authors \cite{Eck2002-blues} go on
to build a system for improvizing blues music, demonstrating the success of
LSTMs on musical data. They decompose the task into modelling chords
then notes, feeding the outputs of a chord LSTM into a melody LSTM.

\cite{Allan2005} uses HMMs to harmonize Bach chorales. \todo{How is this different}

\cite{Brien2016} compared RNN models for Bach chorales. However, their data format does not permit independent
articulation of parts. More importantly, their training implementation resets the LSTM state for each input
sequence, limiting the time-range of learned dynamics to be at most the sequence length.

\cite{Boulanger-Lewandowski2012} propose a RNN-RBM model to model arbitrary
piano roll representations. \todo{Expand upon this} In a RNN-RBM, the hidden
state is used to compute the parameters for a restricted Boltzmann machine at
each timestep. The RBM parameterizess a multivariate categorical distribution,
which can be either over the four parts or the entire piano roll. This work was
extended in \cite{Lyu2015} to yield state of the art results.

\cite{Liu2014} uses LSTMs on Bach chorales.

Computational musicology has been greatly aided by modern tools, including
\texttt{music21} \cite{Scott2015}. \cite{Cuthbert2011} demonstrates machine
learning on rich music representations using \texttt{music21}.

On the music theory side, \cite{Tymoczko2009} proposed three different metrics
for musical data and demonstrated their relationships using tools from geometry
and topology.

LSTM architectures have been adapted for music. \cite{Koutnik2014} proposes a
clockwork RNN, which updates different subvectors of the hidden state at
different periods in order to capture both short-term and long-term dynamics.
\cite{Mikolov2015} proposes the structurally cosntrained RNN (SCRN), a simple
architecture achieving comparable performance to LSTMs.
